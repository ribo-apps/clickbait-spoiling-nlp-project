{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "piRlHltyG5_O",
      "metadata": {
        "id": "piRlHltyG5_O"
      },
      "source": [
        "### **QLoRA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tmlP6jApG_Zr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmlP6jApG_Zr",
        "outputId": "ea78fab6-263f-421f-ec4b-2c773b29c463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-y91zuhjw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-y91zuhjw\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 70c79940957fb25b54bd1b106935c756b90345eb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-uh2ct8c2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-uh2ct8c2\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 189a6b8e357ecda05ccde13999e4c35759596a67\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/huggingface/accelerate.git\n",
            "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-hp6hh4wl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-hp6hh4wl\n",
            "  Resolved https://github.com/huggingface/accelerate.git to commit 543c59af224e3ea273633732319916b0698234ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl\n",
            "  Downloading trl-0.4.4-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0.dev0)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0.dev0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.31.0.dev0)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0.dev0) (3.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (16.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: transformers, peft, accelerate\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.31.0.dev0-py3-none-any.whl size=7169418 sha256=4ec594a60e040256356b8115b6ecd88935df0fc9cfda80ae024f1bc0a1f0710e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h64wjbiy/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=59308 sha256=b419985d0805ae3e4a31e1cf62c08130c62178fc71542149a340fe6915278d8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h64wjbiy/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.21.0.dev0-py3-none-any.whl size=228522 sha256=9e3120732d1ed94382e3f0d39599e50ba1703f99f514b02ee2b10c5544ec3272\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h64wjbiy/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
            "Successfully built transformers peft accelerate\n",
            "Installing collected packages: tokenizers, safetensors, bitsandbytes, xxhash, multidict, frozenlist, einops, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, accelerate, trl, peft\n",
            "Successfully installed accelerate-0.21.0.dev0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bitsandbytes-0.39.0 datasets-2.12.0 dill-0.3.6 einops-0.6.1 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 peft-0.4.0.dev0 responses-0.18.0 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0.dev0 trl-0.4.4 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install bitsandbytes git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/peft.git git+https://github.com/huggingface/accelerate.git datasets trl einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MBWqTu9pZfvJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBWqTu9pZfvJ",
        "outputId": "a9c35746-2221-4564-a556-92112a47b511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers@de9255de27abfcae4a1f816b904915f0b1e23cd9\n",
            "  Cloning https://github.com/huggingface/transformers (to revision de9255de27abfcae4a1f816b904915f0b1e23cd9) to /tmp/pip-req-build-ytcxfn0o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-ytcxfn0o\n",
            "  Running command git rev-parse -q --verify 'sha^de9255de27abfcae4a1f816b904915f0b1e23cd9'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers de9255de27abfcae4a1f816b904915f0b1e23cd9\n",
            "  Running command git checkout -q de9255de27abfcae4a1f816b904915f0b1e23cd9\n",
            "  Resolved https://github.com/huggingface/transformers to commit de9255de27abfcae4a1f816b904915f0b1e23cd9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.0.dev0) (3.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.30.0.dev0-py3-none-any.whl size=7128533 sha256=88a64ac0d3455b821aa3d1b1fce41b42ec0cece934936dd785ee8f7f02646de7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/26/b5/4452a388839f80723ac7d072a45ea6716ce5603db98005244f\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.31.0.dev0\n",
            "    Uninstalling transformers-4.31.0.dev0:\n",
            "      Successfully uninstalled transformers-4.31.0.dev0\n",
            "Successfully installed transformers-4.30.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers@de9255de27abfcae4a1f816b904915f0b1e23cd9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b0eOQeuJ2Ao",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b0eOQeuJ2Ao",
        "outputId": "c6f5f56c-26d9-4f22-a527-5a46cdecc589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OAOrbNL2G01N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAOrbNL2G01N",
        "outputId": "eddd3011-d430-47b7-f8d0-3500c2fb3ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-a100-s-396vj55iios3g --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch, einops\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from peft.tuners.lora import LoraLayer\n",
        "\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ahDWZocKG0x-",
      "metadata": {
        "id": "ahDWZocKG0x-"
      },
      "outputs": [],
      "source": [
        "def create_and_prepare_model():\n",
        "    compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"tiiuae/falcon-7b\", quantization_config=bnb_config, device_map={\"\": 0}, trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    peft_config = LoraConfig(\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        r=64,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\n",
        "            \"query_key_value\"\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b\", trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    return model, peft_config, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xlb_5JNKHMxE",
      "metadata": {
        "id": "xlb_5JNKHMxE"
      },
      "outputs": [],
      "source": [
        "def concat(x):\n",
        "    concated = \"\"\n",
        "    for k, v in x.items():\n",
        "        if k == \"spoiler\":\n",
        "            continue\n",
        "        concated += k + \": \" + str(v) + \"\\n\"\n",
        "    concated += \"spoiler\" + \": \" + x[\"spoiler\"] + \"\\n\"\n",
        "    return concated\n",
        "\n",
        "def concat_val(x):\n",
        "    concated = \"\"\n",
        "    for k, v in x.items():\n",
        "        if k == \"spoiler\" or k==\"provenance\":\n",
        "            continue\n",
        "        concated += k + \": \" + str(v) + \"\\n\"\n",
        "    concated += \"spoiler\" + \": \"\n",
        "    return concated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28nUAbyeHH9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28nUAbyeHH9d",
        "outputId": "40dcdc04-035c-493f-d3be-2d4503c9efa8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-cb7099833d80d600/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
          ]
        }
      ],
      "source": [
        "data = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/NLP_Project/train_changed.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OLvRXud3HRKq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLvRXud3HRKq",
        "outputId": "30d5e3b7-7fa2-4d15-a68f-d218d1dbf1dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-cb7099833d80d600/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-7741bbbcc4044377.arrow\n"
          ]
        }
      ],
      "source": [
        "dataset = data.map(lambda x: {\"text\": concat(x)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1VvefiqlJIvo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VvefiqlJIvo",
        "outputId": "7a3afcae-f991-4e49-c672-dd780283e96d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['postText', 'postPlatform', 'targetParagraphs', 'targetTitle', 'targetDescription', 'targetKeywords', 'provenance', 'spoiler', 'spoilerPositions', 'tags', 'text'],\n",
              "    num_rows: 3197\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hyvg-_QZH2QI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "838c6418a80a40639623ab9a05efc23f",
            "b2e4c8ec4ccc47a8abc981fe5f777220",
            "5e11a7b9e7ca4cb0b05a59cf230ab005",
            "c3063adb763445038fe47b7f2f245215",
            "a29bca8937e641c7a8679caf5eb3c009",
            "10d03f6c0a7f46d6b35824a4b01d093b",
            "1a238f3280cf44c08c6e65dc7a0b789f",
            "f8cb7623f4a942688f631742b169815b",
            "6b0ae3b171384d228cadb0a6313943d3",
            "1bb004d2f45c4d8a8c1bd581d9d7456d",
            "347524b992b840c287a111bb13026e3b"
          ]
        },
        "id": "hyvg-_QZH2QI",
        "outputId": "40d0271a-b8b8-4791-fd8f-03e0b836bdd1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "838c6418a80a40639623ab9a05efc23f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model, peft_config, tokenizer = create_and_prepare_model()\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PBRbbQQhHxIG",
      "metadata": {
        "id": "PBRbbQQhHxIG"
      },
      "outputs": [],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"/content/falcon\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=10,\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    num_train_epochs=10,#max_steps=10000,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DVBqFF2pH6Ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "6aa5acf6b64c4bebbb1dd8a1fd84bd94",
            "6f9f9736cf0043fab56ddfb44bbf403e",
            "7971913f651843389e0e9c74a30da47f",
            "423cee9d26a8430eaccc7df6635906ed",
            "16ec8b10fb024143bc3a1bb7ce20f876",
            "f6700263c3384664b8f06c14b5d3352e",
            "d24ca9fda9094ea6bcb62bb5a8b061ba",
            "fc96823dda044c35a236df7598b0cbc5",
            "65e74326828f454682062c6e768ff28b",
            "cf95a759258444cb9fa08a8162f4e24a",
            "bb1c2092b6584b03ae679415605973e0"
          ]
        },
        "id": "DVBqFF2pH6Ba",
        "outputId": "272ea16c-1e5b-4dd8-b497-2229afcf7460"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aa5acf6b64c4bebbb1dd8a1fd84bd94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3197 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=2048,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tTgP37waIDMj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tTgP37waIDMj",
        "outputId": "3a98c935-d73f-4aca-9987-bd50a57c1f6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [430/430 39:58, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.136500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.137900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.099300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.093800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.124600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.102200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.079100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.022700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.014100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>2.078500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>2.078200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.038800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.988300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.059900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.968100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.953900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.990400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.998200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.874800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.933900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.915700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.783000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.026200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.977500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.896700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.881500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.910900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.916400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.805100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.830100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.774300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.879800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.886200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.777800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.782800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.743400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.845100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=430, training_loss=1.9660607493200968, metrics={'train_runtime': 2403.4628, 'train_samples_per_second': 0.728, 'train_steps_per_second': 0.179, 'total_flos': 7.042619286749184e+16, 'train_loss': 1.9660607493200968, 'epoch': 9.83})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZhM_z0XjWt7s",
      "metadata": {
        "id": "ZhM_z0XjWt7s"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('last-2048-10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IZ3p0dfpSVcd",
      "metadata": {
        "id": "IZ3p0dfpSVcd"
      },
      "outputs": [],
      "source": [
        "def tokenization(example):\n",
        "    return len(tokenizer(example)['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tB-U4nd1Seih",
      "metadata": {
        "id": "tB-U4nd1Seih"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "ddd = [tokenization(x) for x in dataset['text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8B5RvTZoUfu4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B5RvTZoUfu4",
        "outputId": "50dcf681-e2f5-492f-9b00-672b700051fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(np.unique(ddd, return_counts=True)[1][np.unique(ddd, return_counts=True)[0] > 2048])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "df3fd9ff",
      "metadata": {
        "id": "df3fd9ff"
      },
      "source": [
        "### Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1GJyIkAXntm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1GJyIkAXntm",
        "outputId": "2b767b0d-0417-48f0-c3ad-ec0871daf0c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-ad746dc969fc47f0/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
          ]
        }
      ],
      "source": [
        "valdata = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/NLP_Project/validation_changed.json\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZJ19nhQTX13w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ19nhQTX13w",
        "outputId": "9994866f-98d2-4313-811b-eb3a9dc4ca59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-ad746dc969fc47f0/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-10f3a16093ef0181.arrow\n"
          ]
        }
      ],
      "source": [
        "valdataset = valdata.map(lambda x: {\"text\": concat_val(x)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OA576w03YR5S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OA576w03YR5S",
        "outputId": "a7b5f5ac-a9e6-4146-b6ae-0b70639031e5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'postText: Why Arizona Sheriff Joe Arpaio’s fate could hang on a single word\\npostPlatform: reddit\\ntargetParagraphs: © REUTERS/Laura Segall Maricopa County Sheriff Joe Arpaio announces newly launched program aimed at providing security around schools in Anthem, Arizona, January 9, 2013. PHOENIX — A single word — \"intentionally\" — could transform a court case against Phoenix-area Sheriff Joe Arpaio from civil charges to a criminal prosecution.??? In finding Arpaio and three of his top commanders in contempt of court on Friday, U.S. District Court Judge Murray Snow said no fewer than 19 times that the sheriff or his aides had repeatedly and intentionally violated judicial orders to stop profiling Latinos. On May 31, Snow will determine the civil penalties and examine whether Arpaio, the sheriff of Arizona’s Maricopa County, will be referred to Arizona’s U.S. attorney for potential criminal charges.??? Arpaio has acknowledged violating Snow’s order, but said it was a mistake. In weighing criminal charges, Snow must decide whether Arpaio’s violations of his orders were intentional.??? In the meantime, the judge had unusually harsh words for Arpaio.??? \"The Defendants’ unfair, partial, and inequitable application of discipline disproportionally (sic) damaged members of the Plaintiff class,\" Snow wrote.??? In a 2011 civil case brought by Latino drivers against Arpaio and his aides, Snow determined that Arpaio had encouraged his deputies to subject Latino drivers to greater scrutiny during traffic stops than white drivers typically received. He ordered the sheriff to put an end to the practice.??? Two years later, Snow found that Arpaio had continued the practice in violation of the order. At a Houston rally the next year, Arpaio told supporters that he had violated the order \"out of spite\" and had arrested 500 people.??? He later said in court filings that he had violated the order unknowingly.??? In Friday’s ruling, Arpaio was held in contempt on three counts. Chief Deputy Jerry Sheridan was found in contempt on two counts, and retired Chief Brian Sands and Lt. Joe Sousa each were found in contempt on one count.??? \"The Court finds that the Defendants have engaged in multiple acts of misconduct, dishonesty, and bad faith,\" Snow wrote. \"In their testimony during the evidentiary hearing, Sheriff Arpaio and Chief Deputy Sheridan made multiple intentional misstatements of fact while under oath.\"??? In hearings last year, Arpaio, the octogenarian who calls himself \"America’s toughest sheriff,\" seemed to wither under questioning, particularly when asked about an effort he had made to investigate the judge.??? A lawyer for Arpaio had hired a private investigator to look into comments Snow’s wife purportedly made in a restaurant, where an informant claimed she had said the judge didn’t want to see Arpaio reelected.??? Arpaio apologized to Snow for the investigation, but the sheriff’s attorneys also used the incident to argue that Snow was no longer impartial and should recuse himself from the case. Snow declined.??? In his contempt ruling, Snow said Arpaio and his aides failed to turn over video evidence to plaintiffs in the civil case, disobeyed orders to gather evidence and continued to profile Latinos.??? Snow found that Arpaio hid thousands of pieces of evidence from the plaintiffs and deleted relevant digital evidence kept on hard drives.??? Longtime opponents immediately called for the sheriff to resign.??? \"Any public official who has been found guilty of racial profiling and ignores the orders of the court cannot be entrusted with the safety and well-being of the community and should step down in shame,\" the immigrant rights group Puente Arizona said in a statement Friday.??? The ACLU, which brought the original case against Arpaio, demanded stricter oversight and transparency from the sheriff’s office.??? \"Strong remedies are needed to protect the community’s rights, starting with internal investigations that root out and punish misconduct,\" said Cecillia Wang, director of the ACLU’s Immigrants’ Rights Project. \"Willing or not, the sheriff will be made to comply with the law.\"??? The ruling Friday was one of Arpaio’s most serious defeats, but it doesn’t bar him from holding office, and he had already announced his intention to run for a seventh term as sheriff in November.\\ntargetTitle: Why Arizona Sheriff Joe Arpaio’s fate could hang on a single word\\ntargetDescription: <p>A single word — \"intentionally\" — could transform a court case against Phoenix-area Sheriff Joe Arpaio from civil charges to a criminal prosecution.</p>\\ntargetKeywords: None\\nspoilerPositions: [[[0, 197], [0, 212]], [[0, 215], [0, 328]]]\\ntags: [\\'multi\\']\\nspoiler: '"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valdataset['text'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "koS0fxgNZMpI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koS0fxgNZMpI",
        "outputId": "4ccab931-d949-424d-ab41-05e67fe8d701"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RWForCausalLM(\n",
              "  (transformer): RWModel(\n",
              "    (word_embeddings): Embedding(65024, 4544)\n",
              "    (h): ModuleList(\n",
              "      (0-31): 32 x DecoderLayer(\n",
              "        (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): Attention(\n",
              "          (maybe_rotary): RotaryEmbedding()\n",
              "          (query_key_value): Linear4bit(\n",
              "            in_features=4544, out_features=4672, bias=False\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4544, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=64, out_features=4672, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "          )\n",
              "          (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): MLP(\n",
              "          (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
              "          (act): GELU(approximate='none')\n",
              "          (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jL6GTNhOY2qm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL6GTNhOY2qm",
        "outputId": "238d343f-e1f7-47c1-9c17-336b5759fddf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "The model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yygxp6TkgCqQ",
      "metadata": {
        "id": "yygxp6TkgCqQ"
      },
      "outputs": [],
      "source": [
        "def save_nested_strings_to_file(nested_strings, file_path):\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        for inner_list in nested_strings:\n",
        "            file.write('$$$\\n')\n",
        "            for string in inner_list:\n",
        "                file.write(string + '\\n')\n",
        "            file.write('$$$')\n",
        "            file.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nTHzwn4egCkl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTHzwn4egCkl",
        "outputId": "370f60ac-6203-4bcb-c7b2-0d9f37d97667"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2887 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: postText: \"Harry Potter\" alums reunite for new movie\n",
            "postPlatform: Twitter\n",
            "targetParagraphs: The mythology of punk music's evolution can be traced back, more or less, to one singular staple: CBGB. Opened in 1973 in downtown Manhattan's East Village, the nightclub that originally intended to house country, bluegrass and blues music (hint its acronym) quickly became a breeding ground for bands like The Ramones, Talking Heads and The Police, among countless others.??? The legacy of the club, which closed in 2006 over a rent dispute, is on display in a new movie that stars Alan Rickman as bemused owner Hilly Kristal. It's a bit of a departure for anyone more accustomed to seeing Rickman, 67, play sinister Severus Snape in \"Harry Potter\" or Judge Turpin in \"Sweeney Todd.\" The movie also afforded him the opportunity to reunite with fellow Hogwarts alum Rupert Grint, who portrays one-third of derriere-bearing punk band The Dead Boys, alongside Justin Bartha and Bronson Adams. They're joined by a revolving door of notable faces, including Malin Akerman as Debbie Harry, Taylor Hawkins as Iggy Pop, Johnny Galecki as Terry Ork and Ashley Greene as Hilly's daughter Lisa.??? HuffPost Entertainment snagged some phone time with Rickman and Grint, who were candid about their unfamiliarity with CBGB's legacy but effusive about the excitement that came with reconvening for the project. Plus, Grint talks about his own punk phase and Rickman explains what Halloween used to mean for him.??? What are you up to today???? Rickman: I'm in New York. I'm just here for three or four days for \"CBGB\" in New York and then back to work in England.??? Grint: I'm rehearsing a play that will start [in London] in a couple of weeks. Yeah, so that's it.??? Are you enjoying the theater work? Are you more of a theater guy or a film guy???? Grint: I don’t know, really. This is my first theater experience, and it’s very different. I wanted to just try it; it’s something I’ve always wanted to do. Just the thought of it scares me. I’ve kind of put it off for a long time, and I just thought it was a good time to do it. And it’s a great play and a really great cast with a great director, and it was just, yeah, I’m enjoying it.??? Were you familiar with the legacy of CBGB as a breeding ground for the punk-rock scene prior to taking your roles in the movie???? Rickman: I wasn’t familiar with CBGB at all. I didn’t know about it and didn’t know its history. I hadn’t even really heard those four letters put together because at that time I was very much in England as a drama student and an art student, so it’s all been a new discovery to me. Obviously I was aware of some of the bands, but not that they’d all started in a club on the Bowery.??? Grint: I didn't actually know a lot about it. I'd obviously heard of the name and the logo and seen it on T-shirts and stuff like that, but I didn’t really know how prolific it was in discovering some of my favorite bands. I love Talking Heads, and the whole punk thing was something I really loved. So, yeah, it was quite an education learning about it. And also Dead Boys, I wasn’t really familiar with them, and kind of listening and watching them on YouTube was amazing. They just had so much energy, and they were just disgusting. It was incredible.??? Did you grow up listening to the music depicted in the movie???? Rickman: Obviously I was aware of the huge rise of The Police in England, and as an art student I was very much a fan of Talking Heads. And then Blondie, but I wasn’t a hard punk-rock fan at the time. But of course I was also very much around the height of The Beatles and The Stones, so it was like that was the lone star and everything spun off from there. And [Bob] Dylan, very much so. ... England in the ‘60s and the ‘70s was everything that history has said; it was phenomenally exciting, musically. One was very shaped by that.??? Grint: It was that whole era that I liked. I like, obviously, The Sex Pistols and The Clash, Blondie as well, and The Ramones. Some amazing people performed on that stage. ... I went through a real punk phase not that long ago, and yeah, it was probably the reason why I decided to do it, because I have such a love for that.??? Did you dress similarly to the character that you play at any point???? Grint: [Laughs] No, not at all. The dog collar was a new experience for me.??? Not knowing much of the mythology of CBGB, how did you come to learn about your characters???? Rickman: What I really enjoyed and what made it interesting to play was the fact that he happened in direct contrast to the world of the club and what its history became. Because there was this big quiet, contained man who made a club for country music and it never ever played there. Along came punk, and he became like that deus ex machina, I suppose. I watched old interviews and DVDs. I listened to him talking to his mother and his daughter and journalists, so there was a lot of material for me.??? Grint: Yeah, there wasn’t really a whole lot to go on. There are a few videos of him playing live at CBGB and a few interviews I watched. Yeah, and having [Dead Boys guitarist Cheetah Chrome] on set was quite a different thing. I had kind of a little bit of pressure because he was kind of watching every scene, and you’re trying to portray him and do him justice, and it’s quite a challenge.??? So he was on set the whole time???? Grint: Yeah, he has a cameo. He plays the cab driver. He was lovely. He was such a nice guy. I was kind of surprised he was still alive.??? Did he give you any notes while filming???? Grint: Not so much notes. It was just kind of watching him and being around him and listening to his stories and just listening, really, kind of absorbing a lot of that. And he was such a nice guy and we had a good time.??? Was this movie your first instance of nudity on camera???? Grint: Yeah, I guess it was, yeah.??? Were you comfortable with that? How did that go down???? Grint: Weirdly, yeah. It didn’t really feel that big a deal. It just kind of happened. I didn’t really think about it when I was getting ready for it, and yeah, it just kind of happened. I had some sort of sock, modesty thing, contraption. I don’t want to go into too much detail. And yeah, it was just sort of one of those things. There was quite a lot of that in the film. Especially from Justin [Bartha] as well. ... There’s quite a lot of ass in the film.??? You had to try out an American accent in this role. Is there an accent out there that you'd be intimidated to have to use on camera???? Rickman: I think every English actor is nervous of a Newcastle accent. That’s really difficult.??? Grint: It’s quite fun just trying to work on it and get it right. I like that kind of challenge. A couple years ago, I did a film that required me to do a Liverpool accent. I don’t know if you’re familiar with that sound, but that was quite a hard one. It’s quite a harsh sound. But I enjoy that side of things.??? Once you started exploring the role and got into The Dead Boys and their history, did you find yourself enjoying their music? What did you think of the band you were portraying???? Grint: I really love them. I listened to all their songs completely. Their songs are quite hard to play, not easy to listen to. But no, I really love then. I’ve always really wanted to be in a band, so this was kind of an opportunity to experience that. To go on stage and have the whole crowd there and the music.??? Is music something you’d ever pursue???? Grint: I don’t know, probably not. I’ve tried to leverage it, but I just know it’s never going to happen.??? Alan, you often play very dominant roles, very powerful people. What were your thoughts going into a character who was much more loose-goosey? Is it fun to shift gears and play that sort of character???? Rickman: I suppose, in my perspective, I’ve played as many of those as I have the other sort. It’s just some get more publicity or make more money at the box office or something. I’m perfectly happy to be Colonel Brandon in \"Sense & Sensibility\" as I am any of those powerful characters. It’s just part of an actor’s job, and you just alter the colors that you get out of the cupboard.??? How was it to reunite? Had you seen each other since doing press for the eighth \"Harry Potter\" movie???? Rickman: No, because I think we’d both been so busy doing other things. But it was great to see him on the set, and it was great to watch all three of them. I saw Emma [Watson] the other night in London in a restaurant, and I saw Daniel [Radcliffe] recently in London because he was doing a play. It’s great to watch the three of them moving forward into the rest of their lives and being working actors and not trapped by one image.??? Grint: Not really, no, actually. ... I love Alan. He’s always been one of my favorites. But yeah, it was quite weird seeing him in a whole new kind of environment because -- I’m trying to think back -- I don’t think I ever really saw him outside of that wig and cloak.??? Which \"Potter\" co-star would you most like to reunite with???? Grint: There are so many. All of them. I’ve already loved working with them. I like Michael Gambon. He’s so cool; just a remarkable guy. I’ve worked with Julie Walters before as well. I love her, she’s great.??? Now for something more fun. It's October. What's your favorite Halloween costume you've ever worn???? Rickman: [Laughs] The thing about Halloween is, to me, it just means -- because it’s so different in England –- we used to have something called Bonfire Night, and we’d have fireworks. That’s disappeared and I know Halloween’s taken over. Halloween to me as a child was, the family would fill a bowl of water and you’d have apple bobbing in it, and you’d get apples out of a bowl of water. To me it just means a soaking wet shirt.??? Grint: I liked Halloween. It never used to be a big thing when I was kid. We never really did it. But I actually had a good costume not that long ago. The last one, I dressed as a Play-Doh can that I made. You know Play-Doh???? Of course.??? Grint: Well, literally, I actually made it. It was a yellow bin. I cut the bottom out and I just wore a yellow bin with a Play-Doh logo. With a yellow hat. It’s not very practical.??? Do you have a favorite Halloween candy???? Rickman: I don’t even know what that means. The word \"chocolate\" would loom large.??? Grint: A favorite Halloween candy? I don’t really know. I never trick-or-treated when I was younger because we lived on a block of houses that were all just kind of elderly people who were just scared to answer the door. But yeah, candy corn, that’s a big thing. I’ve tried that. That’s pretty great.??? \"CBGB\" is out in limited release now.\n",
            "targetTitle: Alan Rickman & Rupert Grint On 'CBGB,' Reuniting Post-'Potter' And Favorite Halloween Costumes\n",
            "targetDescription: The mythology of punk music's evolution can be traced back, more or less, to one singular staple: CBGB. Opened in 1973 in downtown Manhattan's East Villa...\n",
            "targetKeywords: Alan Rickman,Hilly Kristal,new rupert grint movie,rupert grint harry potter,new alan rickman movie,Alan Rickman Snape,alan rickman rupert grint,The Dead Boys,cbgb,Malin Akerman,cbgb movie,alan rickman cbgb,rupert grint cbgb,Rupert Grint,Taylor Hawkins,ashley greene\n",
            "spoilerPositions: [[[-1, 0], [-1, 27]], [[0, 98], [0, 102]]]\n",
            "tags: ['multi']\n",
            "spoiler: [The \"Spike and Twisted Sister and I have nothing on their resume. Rupert Grint, Rupert Grint, Taylor Hawkins,harry potter and the dead boys,new Rupert Grint, Rupert Grin's Grin's Grint,alice hilton,alice hilton movie,alice hilton,alice hilton harry potter & The Grin's Grin's Grin's Grin's Grin's Grint: [0]\n",
            "spoil\n",
            "spoilerPositions: [1 to [0] the dead\n"
          ]
        }
      ],
      "source": [
        "sequences = pipeline(\n",
        "    valdataset['text'][3],\n",
        "    max_new_tokens=128,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        ")\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ntyTgGZxY7c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntyTgGZxY7c1",
        "outputId": "10825155-d1e6-4ab7-d197-678a9cdb1c89"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "save_list =[]\n",
        "for text in tqdm(valdataset['text']):\n",
        "    sequences = pipeline(\n",
        "        text,\n",
        "        max_new_tokens=128,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    output = []\n",
        "    for seq in sequences:\n",
        "        output.append(seq['generated_text'])\n",
        "        #print(f\"Result: {seq['generated_text']}\")\n",
        "    save_list.append(output)\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9lXhikzD7y-G",
      "metadata": {
        "id": "9lXhikzD7y-G"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XZloZPSdhUfb",
      "metadata": {
        "id": "XZloZPSdhUfb"
      },
      "outputs": [],
      "source": [
        "save_nested_strings_to_file(save_list, \"/content/drive/MyDrive/NLP_Project/falcon/val_2048_10_200.txt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "papermill": {
      "default_parameters": {},
      "duration": null,
      "end_time": null,
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-06-07T22:02:09.458370",
      "version": "2.4.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10d03f6c0a7f46d6b35824a4b01d093b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ec8b10fb024143bc3a1bb7ce20f876": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1a238f3280cf44c08c6e65dc7a0b789f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bb004d2f45c4d8a8c1bd581d9d7456d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347524b992b840c287a111bb13026e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "423cee9d26a8430eaccc7df6635906ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf95a759258444cb9fa08a8162f4e24a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb1c2092b6584b03ae679415605973e0",
            "value": " 3197/3197 [00:02&lt;00:00, 1387.81 examples/s]"
          }
        },
        "5e11a7b9e7ca4cb0b05a59cf230ab005": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8cb7623f4a942688f631742b169815b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b0ae3b171384d228cadb0a6313943d3",
            "value": 2
          }
        },
        "65e74326828f454682062c6e768ff28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6aa5acf6b64c4bebbb1dd8a1fd84bd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f9f9736cf0043fab56ddfb44bbf403e",
              "IPY_MODEL_7971913f651843389e0e9c74a30da47f",
              "IPY_MODEL_423cee9d26a8430eaccc7df6635906ed"
            ],
            "layout": "IPY_MODEL_16ec8b10fb024143bc3a1bb7ce20f876"
          }
        },
        "6b0ae3b171384d228cadb0a6313943d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f9f9736cf0043fab56ddfb44bbf403e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6700263c3384664b8f06c14b5d3352e",
            "placeholder": "​",
            "style": "IPY_MODEL_d24ca9fda9094ea6bcb62bb5a8b061ba",
            "value": "Map: 100%"
          }
        },
        "7971913f651843389e0e9c74a30da47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc96823dda044c35a236df7598b0cbc5",
            "max": 3197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65e74326828f454682062c6e768ff28b",
            "value": 3197
          }
        },
        "838c6418a80a40639623ab9a05efc23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2e4c8ec4ccc47a8abc981fe5f777220",
              "IPY_MODEL_5e11a7b9e7ca4cb0b05a59cf230ab005",
              "IPY_MODEL_c3063adb763445038fe47b7f2f245215"
            ],
            "layout": "IPY_MODEL_a29bca8937e641c7a8679caf5eb3c009"
          }
        },
        "a29bca8937e641c7a8679caf5eb3c009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e4c8ec4ccc47a8abc981fe5f777220": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d03f6c0a7f46d6b35824a4b01d093b",
            "placeholder": "​",
            "style": "IPY_MODEL_1a238f3280cf44c08c6e65dc7a0b789f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "bb1c2092b6584b03ae679415605973e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3063adb763445038fe47b7f2f245215": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bb004d2f45c4d8a8c1bd581d9d7456d",
            "placeholder": "​",
            "style": "IPY_MODEL_347524b992b840c287a111bb13026e3b",
            "value": " 2/2 [00:17&lt;00:00,  7.85s/it]"
          }
        },
        "cf95a759258444cb9fa08a8162f4e24a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24ca9fda9094ea6bcb62bb5a8b061ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6700263c3384664b8f06c14b5d3352e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cb7623f4a942688f631742b169815b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc96823dda044c35a236df7598b0cbc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
